{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c69d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom modules\n",
    "from model_explainability import FraudModelExplainer\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc923db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: LOAD TRAINED MODEL AND DATA\n",
      "================================================================================\n",
      "âœ“ Model loaded: RandomForestClassifier\n",
      "\n",
      "ðŸ“Š Data shapes:\n",
      "X_train: (8000, 88)\n",
      "X_test: (2000, 88)\n",
      "y_train: (8000,)\n",
      "y_test: (2000,)\n",
      "\n",
      "ðŸ”¤ Features: 88 total\n",
      "First 10 features: ['v0', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Model and Data\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: LOAD TRAINED MODEL AND DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load best model from Task 2\n",
    "model_path = r'C:\\Users\\admin\\fraud-detection-week5\\models\\best_model_Random Forest.pkl'\n",
    "model = joblib.load(model_path)\n",
    "print(f\"âœ“ Model loaded: {type(model).__name__}\")\n",
    "\n",
    "# Load transformed data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').squeeze(\"columns\")\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').squeeze(\"columns\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X_train.columns.tolist()\n",
    "print(f\"\\nðŸ”¤ Features: {len(feature_names)} total\")\n",
    "print(f\"First 10 features: {feature_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1fbeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: INITIALIZE MODEL EXPLAINER\n",
      "================================================================================\n",
      "âœ“ Model explainer initialized\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize Model Explainer\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: INITIALIZE MODEL EXPLAINER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize explainer\n",
    "explainer = FraudModelExplainer(\n",
    "    model=model,\n",
    "    feature_names=feature_names,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model explainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680d2c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: BUILT-IN FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "BUILT-IN FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "âœ— Error extracting built-in importance: All arrays must be of the same length\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract Built-in Feature Importance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: BUILT-IN FEATURE IMPORTANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract built-in importance\n",
    "builtin_importance = explainer.extract_builtin_feature_importance(top_n=15)\n",
    "\n",
    "if builtin_importance is not None:\n",
    "    print(f\"\\nâœ… Extracted built-in importance for {len(builtin_importance)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19682381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: COMPUTE SHAP VALUES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPUTING SHAP VALUES\n",
      "================================================================================\n",
      "SHAP (SHapley Additive exPlanations) values explain individual predictions\n",
      "ðŸ“Š Using 1,000 samples for SHAP computation (50.0% of data)\n",
      "ðŸŒ³ Using TreeExplainer for tree-based model\n",
      "âœ… SHAP values computed successfully\n",
      "   Shape: (1000, 88)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Compute SHAP Values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: COMPUTE SHAP VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "explainer = FraudModelExplainer(model=model, feature_names=feature_names)\n",
    "explainer.compute_shap_values(X_test, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a482472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4: COMPUTE SHAP VALUES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPUTING SHAP VALUES\n",
      "================================================================================\n",
      "SHAP (SHapley Additive exPlanations) values explain individual predictions\n",
      "ðŸ“Š Using 1,000 samples for SHAP computation (50.0% of data)\n",
      "ðŸŒ³ Using TreeExplainer for tree-based model\n",
      "âœ… SHAP values computed successfully\n",
      "   Shape: (1000, 88)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Compute SHAP Values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: COMPUTE SHAP VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "explainer = FraudModelExplainer(model=model, feature_names=feature_names)\n",
    "explainer.compute_shap_values(X_test, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c618c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5: SHAP SUMMARY PLOT (GLOBAL IMPORTANCE)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SHAP SUMMARY PLOT (Global Feature Importance)\n",
      "================================================================================\n",
      "Shows feature importance and impact direction across all predictions\n",
      "âœ— Error creating SHAP summary plot: index 1860 is out of bounds for axis 0 with size 1000\n"
     ]
    }
   ],
   "source": [
    "# Step 5: SHAP Summary Plot\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: SHAP SUMMARY PLOT (GLOBAL IMPORTANCE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create SHAP summary plot\n",
    "explainer.plot_shap_summary(X_test, max_display=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7e9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 6: SHAP FORCE PLOTS (INDIVIDUAL PREDICTIONS)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SHAP FORCE PLOTS (Individual Predictions)\n",
      "================================================================================\n",
      "Shows how each feature contributes to individual predictions\n",
      "âœ— Error creating force plots: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Step 6: SHAP Force Plots\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: SHAP FORCE PLOTS (INDIVIDUAL PREDICTIONS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create SHAP force plots for interesting cases\n",
    "explainer.plot_shap_force_plots(X_test, y_test, n_cases=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "828b84d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 7: FEATURE IMPORTANCE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE COMPARISON\n",
      "================================================================================\n",
      "Comparing built-in importance with SHAP importance\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Feature Importance Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: FEATURE IMPORTANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare built-in vs SHAP importance\n",
    "importance_comparison = explainer.compare_feature_importance(\n",
    "    builtin_importance=builtin_importance,\n",
    "    top_n=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1310ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 8: BUSINESS RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "BUSINESS RECOMMENDATIONS\n",
      "================================================================================\n",
      "Actionable insights derived from model explainability\n",
      "âœ— Error generating business recommendations: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "âœ… Business recommendations generated\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Generate Business Recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate actionable business recommendations\n",
    "recommendations = explainer.generate_business_recommendations(\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Business recommendations generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c68d1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 9: COMPLETE EXPLAINABILITY REPORT\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXPLAINABILITY REPORT SUMMARY\n",
      "================================================================================\n",
      "Shap Values Computed: True\n",
      "Explainer Available: True\n",
      "Total Features: 88\n",
      "Analysis Completed: False\n",
      "\n",
      "ðŸ’¾ Explainability report saved to: ../reports/explainability_report.json\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Generate Complete Explainability Report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: COMPLETE EXPLAINABILITY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate comprehensive report\n",
    "explainability_report = explainer.generate_explainability_report()\n",
    "\n",
    "# Save report\n",
    "import json\n",
    "report_path = '../reports/explainability_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(explainability_report, f, indent=2)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Explainability report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90899ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK 3 SUMMARY - KEY FINDINGS\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ TOP 5 FRAUD INDICATORS (from SHAP analysis):\n",
      "\n",
      "1. v3:\n",
      "   SHAP Importance: 0.1194\n",
      "   Avg for fraud: 1.55\n",
      "   Avg for non-fraud: -0.03\n",
      "\n",
      "2. v4:\n",
      "   SHAP Importance: 0.0951\n",
      "   Avg for fraud: 1.37\n",
      "   Avg for non-fraud: -0.04\n",
      "\n",
      "3. v5:\n",
      "   SHAP Importance: 0.0364\n",
      "   Avg for fraud: 0.03\n",
      "   Avg for non-fraud: -0.01\n",
      "\n",
      "4. v2:\n",
      "   SHAP Importance: 0.0342\n",
      "   Avg for fraud: -0.13\n",
      "   Avg for non-fraud: -0.01\n",
      "\n",
      "5. v8:\n",
      "   SHAP Importance: 0.0342\n",
      "   Avg for fraud: -0.16\n",
      "   Avg for non-fraud: -0.05\n",
      "\n",
      "================================================================================\n",
      "TASK 3 COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary of Key Findings\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 3 SUMMARY - KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸŽ¯ TOP 5 FRAUD INDICATORS (from SHAP analysis):\")\n",
    "\n",
    "# Extract top features from SHAP\n",
    "shap_values = explainer.shap_values\n",
    "if shap_values is not None:\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "    top_indices = np.argsort(shap_importance)[-5:][::-1]\n",
    "    \n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        feature = feature_names[idx]\n",
    "        importance = shap_importance[idx]\n",
    "        \n",
    "        # Get statistics\n",
    "        fraud_mean = X_test[y_test == 1][feature].mean()\n",
    "        nonfraud_mean = X_test[y_test == 0][feature].mean()\n",
    "        \n",
    "        print(f\"\\n{i}. {feature}:\")\n",
    "        print(f\"   SHAP Importance: {importance:.4f}\")\n",
    "        print(f\"   Avg for fraud: {fraud_mean:.2f}\")\n",
    "        print(f\"   Avg for non-fraud: {nonfraud_mean:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 3 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
